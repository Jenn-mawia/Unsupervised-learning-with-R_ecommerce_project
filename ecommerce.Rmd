---
title: "E-Commerce analysis with clustering"
author: "Jenipher Mawia"
date: "11/5/2020"
output: html_document
---

# 1. Problem Definition

## 1.1 Defining the question
Perform clustering on the following data [link](http://bit.ly/EcommerceCustomersDataset) stating insights drawn from your analysis and visualizations drawn towards learning the characteristics of customer groups.

## 1.2 Specifying the question
Implement the solution using unsupervised learning techniques such as **K-means clustering** and **hierarchical clustering**.

# 2. Defining the metrics for success
This project will be considered a success if the following are achieved:
- Unsupervised learning models are built (K-means and hierarchical clustering).
- Insights are drawn from the EDA process and modeling.

# 3. The Context
[Kira Plastinina](https://kiraplastinina.ru/) is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

# 4. Experimental Design taken
The following is the order in which I went about to achieve the objectives of this project:

- Data Sourcing and Understanding
- Checking the data (head and tail, shape(number of records), datatypes)
- Data cleaning procedures (handling null values,outliers, anomalies)
- Exploratory data analysis (Univariate, Bivariate and Multivariate analyses)
- Implementing the solution(Clustering)
- Conclusion and recommendation
- Challenging the solution
- Follow-up questions

# 5. Data Sourcing
The data used for this project was sourced from the following [website](https://kiraplastinina.ru/) and can be downloaded [here](http://bit.ly/EcommerceCustomersDataset)

### Reading the data

```{r}
ecommerce <- read.csv("http://bit.ly/EcommerceCustomersDataset")
```

# 6. Checking the Data
### checking the top of the data

```{r}
# checking the first 6 rows in the data
head(ecommerce)
```

### checking the bottom of the data

```{r}
# checking the last 6 rows in the data
tail(ecommerce)
```

### checking the shape of the data

```{r}
# checking the dimensions of the data (number of entries and fields)
dim(ecommerce)
```

The data has 12330 entries and 18 columns. 

### checking the datatypes of the column

```{r}
# getting the datatypes of each column
str(ecommerce)
```

The data consists of integer, numeric, character and logical dataypes. The first 10 columns are numerical attributes while the last 8 columns are categorical attributes. 

# 7. Appropriateness of the available data to answer the given question

The data contains columns such as: 

- "Administrative", "Administrative Duration", "Informational", "Informational Duration", "Product Related" and "Product Related Duration" represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another. 
- The "Bounce Rate", "Exit Rate" and "Page Value" features represent the metrics measured by "Google Analytics" for each page in the e-commerce site. 
- The value of the "Bounce Rate" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session. 
- The value of the "Exit Rate" feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.
- The "Page Value" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. 
- The "Special Day" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. 
- The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.

All these fields are useful in learning the characteristics of customer groups and will play a great role in answering our research question. 

Therefore, it can be concluded that the data available is appropriate and relevant to answer the given question.

# 8. Data Cleaning

### 8.1 Standardizing the column names to similar formatting

From the above outputs, we can see that the column names are not in a standard/similar format. This needs to be addressed:

```{r}
# get the column names
colnames(ecommerce)
```

```{r}
# changing the column names to a standard format
names(ecommerce)[names(ecommerce) == "Administrative"] <- "administrative"
names(ecommerce)[names(ecommerce) == "Administrative_Duration"] <- "administrative_duration"
names(ecommerce)[names(ecommerce) == "Informational"] <- "informational"
names(ecommerce)[names(ecommerce) == "Informational_Duration"] <- "informational_duration"
names(ecommerce)[names(ecommerce) == "ProductRelated"] <- "product_related"
names(ecommerce)[names(ecommerce) == "ProductRelated_Duration"] <- "product_related_duration"
names(ecommerce)[names(ecommerce) == "BounceRates"] <- "bounce_rates"
names(ecommerce)[names(ecommerce) == "ExitRates"] <- "exit_rates"
names(ecommerce)[names(ecommerce) == "PageValues"] <- "page_values"
names(ecommerce)[names(ecommerce) == "SpecialDay"] <- "special_day"
names(ecommerce)[names(ecommerce) == "Month"] <- "month"
names(ecommerce)[names(ecommerce) == "OperatingSystems"] <- "operating_systems"
names(ecommerce)[names(ecommerce) == "Browser"] <- "browser"
names(ecommerce)[names(ecommerce) == "Region"] <- "region"
names(ecommerce)[names(ecommerce) == "TrafficType"] <- "traffic_type"
names(ecommerce)[names(ecommerce) == "VisitorType"] <- "visitor_type"
names(ecommerce)[names(ecommerce) == "Weekend"] <- "weekend"
names(ecommerce)[names(ecommerce) == "Revenue"] <- "revenue"
```


```{r}
#confirm changes made
colnames(ecommerce)
```

### 8.2 Duplicated entries

```{r}
#checking for duplicated entries
duplicates <- ecommerce[duplicated(ecommerce),]
duplicates
```

There is a total of 119 duplicated records in the data. We will remove them since duplicated  data may imply inaccurate reporting and thus lead to less informed decisions.

```{r}
# removing duplicated data
ecommerce_unique <- unique(ecommerce)

# confirming from the data for any duplicated records
anyDuplicated(ecommerce_unique)
```

### 8.3 Missing data

```{r}
#check for missing data per column
colSums(is.na(ecommerce_unique))
```
Since the missing values occur in the numerical columns only, they can be filled with the means of the columns
```{r}
# recode missing values with the means 
ecommerce_unique$administrative[is.na(ecommerce_unique$administrative)] <- mean(ecommerce_unique$administrative, na.rm = TRUE)

ecommerce_unique$administrative_duration[is.na(ecommerce_unique$administrative_duration)] <- mean(ecommerce_unique$administrative_duration, na.rm = TRUE)

ecommerce_unique$informational[is.na(ecommerce_unique$informational)] <- mean(ecommerce_unique$informational, na.rm = TRUE)

ecommerce_unique$informational_duration[is.na(ecommerce_unique$informational_duration)] <- mean(ecommerce_unique$informational_duration, na.rm = TRUE)

ecommerce_unique$product_related[is.na(ecommerce_unique$product_related)] <- mean(ecommerce_unique$product_related, na.rm = TRUE)

ecommerce_unique$product_related_duration[is.na(ecommerce_unique$product_related_duration)] <- mean(ecommerce_unique$product_related_duration, na.rm = TRUE)

ecommerce_unique$bounce_rates[is.na(ecommerce_unique$bounce_rates)] <- mean(ecommerce_unique$bounce_rates, na.rm = TRUE)

ecommerce_unique$exit_rates[is.na(ecommerce_unique$exit_rates)] <- mean(ecommerce_unique$exit_rates, na.rm = TRUE)
```

```{r}
# confirm from the data for any more missing values
colSums(is.na(ecommerce_unique))
```

### 8.4 Outliers

These are data points that occur far away from the other points in the data. They could cause inconsistencies by distorting summaries of the distribution of values. We can screen for outliers by plotting boxplots of numerical columns in the data. 

```{r}
# get numerical columns in the data
nums <- unlist(lapply(ecommerce_unique, is.numeric))
nums
```

Out of the total 18 columns, there are 14 columns that contain numerical data. However, some of these columns are categorical in nature but do contain numerical data. 

```{r}
# output the numeric columns in form of a dataframe and check the top of the  resulting dataframe
numeric_cols <- ecommerce_unique[ , nums]
head(numeric_cols)
```

```{r}
# make multiple boxplots of the numerical columns to check for any outliers present
par ( mfrow= c (  2, 4 ))
for (i in 1 : length (numeric_cols)) {
boxplot (numeric_cols[,i], main= names (numeric_cols[i]), type= "l" )
}
```

From the boxplots above, there are a couple number of outliers in the numeric columns


```{r}
colnames(ecommerce_unique)
# checking to see the unique values of the categorical columns
unique(ecommerce_unique$operating_systems)

unique(ecommerce_unique$browser)

unique(ecommerce_unique$region)

unique(ecommerce_unique$traffic_type)

unique(ecommerce_unique$special_day)

```

Since values in the categorical columns are discrete in nature, removing outliers will make a poor representation of the original data. Hence, we will only deal with the outliers in the numerical columns with continuos data. 

#### 8.4.1 Dealing with outliers

**Capping**

```{r}
# capping
# administrative
qnt <- quantile (ecommerce_unique$administrative, probs= c (.25 , .75 ), na.rm = T)
caps <- quantile (ecommerce_unique$administrative, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$administrative, na.rm = T)
ecommerce_unique$administrative[ecommerce_unique$administrative < (qnt[ 1 ] - H)] <- caps[ 1 ]
ecommerce_unique$administrative[ecommerce_unique$administrative > (qnt[ 2 ] + H)] <- caps[ 2 ]

# administrative_duration
qnt1 <- quantile (ecommerce_unique$administrative_duration, probs= c (.25 , .75 ), na.rm = T)
caps1 <- quantile (ecommerce_unique$administrative_duration, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$administrative_duration, na.rm = T)
ecommerce_unique$administrative_duration[ecommerce_unique$administrative_duration < (qnt1[ 1 ] - H)] <- caps1[ 1 ]
ecommerce_unique$administrative_duration[ecommerce_unique$administrative_duration > (qnt1[ 2 ] + H)] <- caps1[ 2 ]

# informational
qnt2 <- quantile (ecommerce_unique$informational, probs= c (.25 , .75 ), na.rm = T)
caps2 <- quantile (ecommerce_unique$informational, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$informational, na.rm = T)
ecommerce_unique$informational[ecommerce_unique$informational < (qnt2[ 1 ] - H)] <- caps2[ 1 ]
ecommerce_unique$informational[ecommerce_unique$informational > (qnt2[ 2 ] + H)] <- caps2[ 2 ]

# informational_duration
qnt3 <- quantile (ecommerce_unique$informational_duration, probs= c (.25 , .75 ), na.rm = T)
caps3 <- quantile (ecommerce_unique$informational_duration, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$informational_duration, na.rm = T)
ecommerce_unique$informational_duration[ecommerce_unique$informational_duration < (qnt3[ 1 ] - H)] <- caps3[ 1 ]
ecommerce_unique$informational_duration[ecommerce_unique$informational_duration > (qnt3[ 2 ] + H)] <- caps3[ 2 ]

# product_related
qnt4 <- quantile (ecommerce_unique$product_related, probs= c (.25 , .75 ), na.rm = T)
caps4 <- quantile (ecommerce_unique$product_related, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$product_related, na.rm = T)
ecommerce_unique$product_related[ecommerce_unique$product_related < (qnt4[ 1 ] - H)] <- caps4[ 1 ]
ecommerce_unique$product_related[ecommerce_unique$product_related > (qnt4[ 2 ] + H)] <- caps4[ 2 ]

# product_related_duration
qnt5 <- quantile (ecommerce_unique$product_related_duration, probs= c (.25 , .75 ), na.rm = T)
caps5 <- quantile (ecommerce_unique$product_related_duration, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$product_related_duration, na.rm = T)
ecommerce_unique$product_related_duration[ecommerce_unique$product_related_duration < (qnt5[ 1 ] - H)] <- caps5[ 1 ]
ecommerce_unique$product_related_duration[ecommerce_unique$product_related_duration > (qnt5[ 2 ] + H)] <- caps5[ 2 ]

# bounce_rates
qnt6 <- quantile (ecommerce_unique$bounce_rates, probs= c (.25 , .75 ), na.rm = T)
caps6 <- quantile (ecommerce_unique$bounce_rates, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$bounce_rates, na.rm = T)
ecommerce_unique$bounce_rates[ecommerce_unique$bounce_rates < (qnt6[ 1 ] - H)] <- caps6[ 1 ]
ecommerce_unique$bounce_rates[ecommerce_unique$bounce_rates > (qnt6[ 2 ] + H)] <- caps6[ 2 ]

# exit_rates
qnt7 <- quantile (ecommerce_unique$exit_rates, probs= c (.25 , .75 ), na.rm = T)
caps7 <- quantile (ecommerce_unique$exit_rates, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$exit_rates, na.rm = T)
ecommerce_unique$exit_rates[ecommerce_unique$exit_rates < (qnt7[ 1 ] - H)] <- caps7[ 1 ]
ecommerce_unique$exit_rates[ecommerce_unique$exit_rates > (qnt7[ 2 ] + H)] <- caps7[ 2 ]

# page_values
qnt8 <- quantile (ecommerce_unique$page_values, probs= c (.25 , .75 ), na.rm = T)
caps8 <- quantile (ecommerce_unique$page_values, probs= c (.05 , .95 ), na.rm = T)
H <- 1.5 * IQR (ecommerce_unique$page_values, na.rm = T)
ecommerce_unique$page_values[ecommerce_unique$page_values < (qnt8[ 1 ] - H)] <- caps8[ 1 ]
ecommerce_unique$page_values[ecommerce_unique$page_values > (qnt8[ 2 ] + H)] <- caps8[ 2 ]

```

To see the effects of the changes made, we will make another plot of boxplots to check or outliers present

```{r}
# get numerical columns in the data
nums <- unlist(lapply(ecommerce_unique, is.numeric))

# output the numeric columns in form of a dataframe
numeric_cols <- ecommerce_unique[ , nums]

# make boxplots
par ( mfrow= c (  2, 4 ))
for (i in 1 : length (numeric_cols)) {
boxplot (numeric_cols[,i], main= names (numeric_cols[i]), type= "l" )
}

```

From the plots, we can see there are few to no outliers in the columns containing continuos numerical data. We will not deal with outliers in categorical data to avoid causing a lot of inconsistencies. 

### 8.5 Anomalies
Anomalies are inconsistencies in the data and this can be checked for in many ways. These are rare items, events or observations which raise suspicions by differing significantly from the majority of the data.

### 8.6 Data-type Conversion

Columns containing discrete data(categorical data) needs to be converted to its appropriate form- factor dataype. 

```{r}
# to be revisited
```

# 9. Exploratory Data Analysis

### 9.1 Univariate Data Analysis

#### 9.1.1 Measures of Central Tendency

**Mean**

Get the mean of all numerical columns

```{r}
# get numerical columns and save them on a new dataframe that will be used for analysis
numerical <- ecommerce_unique[c(1,2,3,4,5,6,7,8,9,10)]
# get the means of each column
colMeans(numerical)
```

**Median**

Get the median of all numerical columns

```{r}
apply (numerical, 2 ,median)
```

***Mode**

**Administrative**

```{r}
# Create the function.
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Calculate the mode using the user function.
getmode (ecommerce_unique$administrative)
```

Most users visiting the site did not visit administrative types of pages. 

**administrative_duration**

```{r}
getmode(ecommerce_unique$administrative_duration)
```

Since most users did not visit administrative page types, it is expected that the total time spent in this page category will be zero, which is true from the computed mode. 

**Informational**

```{r}
getmode(ecommerce_unique$informational)
```

Here again, most users visiting the site did not visit a page related to informational category.

**Informational duration**

```{r}
getmode(ecommerce_unique$informational_duration)

```

As expected, the mode of the duration of time users take on pages related to the category "Informational" is zero.

**Product Related**

```{r}
getmode(ecommerce_unique$product_related)

```

The modal number of pages that a user visits related to the category "Product" is 110. 

**Product related duration**

```{r}
getmode(ecommerce_unique$product_related_duration)

```

The most occuring total time spent by a user on Product related page categories is 4312.682

**Bounce Rates**

```{r}
getmode(ecommerce_unique$bounce_rates)

```

The modal percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session is 0%.

**Exit rates**

```{r}
getmode(ecommerce_unique$exit_rates)

```

For all pageviews to the page, the modal percentage that was the last in the session is 0.175

**Page Values**

```{r}
getmode(ecommerce_unique$page_values)

```

The modal average value for a web page that a user visited before completing an e-commerce transaction is 0. 

**Special Day**

```{r}
getmode(ecommerce_unique$special_day)

```

The modal value of closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction is 0. This shows that special days do not have a significant effect on determining whether a user will visit the site to make a purchase or not. 

**Month**

```{r}
getmode(ecommerce_unique$month)

```

The modal month is May. It appears that most users visited the site during this month. Could it be because of a possible mid-year sale offered by the e-commerce site? 

**Visitor Type**

```{r}
getmode(ecommerce_unique$visitor_type)

```

Most users visiting the site are "Returning Visitors". These are visitors who are not new to the site. 

```{r}
getmode(ecommerce_unique$weekend)

```

Most users visit the site during weekdays. 

```{r}
getmode(ecommerce_unique$revenue)
```

Most users visiting the site did not purchase and hence revenue was not made from most visits. 

#### 9.1.2 Measures of Dispersion

##### Find the minimum, maximum and quantiles of the columns in the data.

```{r}
summary(ecommerce_unique)
```

##### Range

Range is the difference between the maximum point and the minimum point in a set of data. 

**Administrative**
```{r}
# Get the range of each numerical column
range(ecommerce_unique$administrative)
```

Pages of the administrative category range from 0-10

**Administrative duration**

```{r}
range(ecommerce_unique$administrative_duration)
```

The range of total time spent by a user on administrative pages is -1 to 352.1702. 

**Informational**

```{r}
range(ecommerce_unique$informational)
```

The range of informational pages is 0-3.

**Informational Duration**

```{r}
range(ecommerce_unique$informational_duration)
```

The total time a user spends on informational pages ranges between 0-199 minutes. 

**Product related**

```{r}
range(ecommerce_unique$product_related)
```

Product related pages range between 0-110.

**Product related duration**

```{r}
range(ecommerce_unique$product_related_duration)
```

The total time a user spends time on product related pages ranges from -1 to 4312.682 minutes

**Bounce rates**

```{r}
range(ecommerce_unique$bounce_rates)
```

The percentage range of bounce rates is between 0-0.15

**Exit rates**

```{r}
range(ecommerce_unique$exit_rates)
```

The percentage range of exit rates is between 0-0.175

**Page Values**

```{r}
range(ecommerce_unique$page_values)
```

The average value of a web page that a user visited before completing an e-commerce transaction ranges between 0-38.2909.

**Special day**

```{r}
range(ecommerce_unique$special_day)
```

Special days range between 0 and 1. 0 being- not close to a special day and 1 means a user visited the site on a day closer to a special day such as Mother's day. 

##### Interquartile Range

The interquartile range also commonly known as IQR is the range between the 1st and 3rd
quantiles. It is the difference between the two quantiles.

**Administrative**
```{r}
IQR(ecommerce_unique$administrative)
```
**Administrative duration**
```{r}
IQR(ecommerce_unique$administrative_duration)
```

**Informational**
```{r}
IQR(ecommerce_unique$informational)
```

**Informational duration**
```{r}
IQR(ecommerce_unique$informational_duration)
```

**Product related**
```{r}
IQR(ecommerce_unique$product_related)
```

**Product related duration**
```{r}
IQR(ecommerce_unique$product_related_duration)
```

**Bounce rates**
```{r}
IQR(ecommerce_unique$bounce_rates)
```

**Exit rates**
```{r}
IQR(ecommerce_unique$exit_rates)
```

**Page values**
```{r}
IQR(ecommerce_unique$page_values)
```

**Special day**
```{r}
IQR(ecommerce_unique$special_day)
```

##### Standard Deviation

Find the standard deviation of the various columns in the data
```{r}
apply (numerical, 2 ,sd)
```

##### Variance

Find the variance of the numerical columns
```{r}
sapply (numerical, var)
```

##### Histograms
```{r}
par( mfrow= c ( 2 , 4 ))
for(i in 1 : length(numerical)) {
hist(numerical[,i], main= names(numerical[i]))
}
```

Most of the data is skewed to the right. 

### 9.2 Bivariate and Multivariate analysis

Since our target variable is Revenue, we will investigate its relationship with the other variables.  

```{r}
# how often does a user make a purchase on the site if he/she visits administrative pages
adm_revenue <- table(ecommerce_unique$administrative, ecommerce_unique$revenue)
names(dimnames(adm_revenue)) <- c("admin" , "revenue" )
adm_revenue
```

Most site visits that did not result in revenue had most users visiting administrative pages.

```{r}
# does time spent on administrative pages result in purchase
adm_duration_revenue <- table(ecommerce_unique$administrative_duration, ecommerce_unique$revenue)
names(dimnames(adm_duration_revenue)) <- c ("admin duration" , "revenue")

head(adm_duration_revenue)

tail(adm_duration_revenue)
```

Most users that did not spend time on administrative pages made a purchase on the ecommerce site and resulted in revenue for the ecommerce company.

```{r}
# how often does a user make a purchase on the site if he/she visits informational pages
info_revenue <- table(ecommerce_unique$informational, ecommerce_unique$revenue)
names(dimnames(info_revenue)) <- c ( "informational" , "revenue" )
info_revenue
```

Most site visitors who did not visit informational pages made a purchase and resulted in revenue for the ecommerce company. 

```{r}
# does time spent on informational pages result in revenue?
info_duration_revenue <- table(ecommerce_unique$informational_duration, ecommerce_unique$revenue)
names(dimnames(info_duration_revenue)) <- c ( "info duration" , "revenue" )
info_duration_revenue
```

Most users who spent a lot of time on informational pages did not result in revenue for the ecommerce company while those who did not visit this category of pages made a purchase from the ecommerce site.

```{r}
# how often does a user make a purchase on the site if he/she visits product related pages
prod_revenue <- table(ecommerce_unique$product_related, ecommerce_unique$revenue)
names(dimnames(prod_revenue)) <- c ( "Prod_related" , "revenue" )
prod_revenue
```

Product related pages 1-31 had the most number of visits in general and with the higher number of revenue returned. Page 110 also had a higher number of visits and more revenue from it was generated. 

```{r}
# does the duration of time spent on product related pages result in revenue?
prod_duration_revenue <- table(ecommerce_unique$product_related_duration, ecommerce_unique$revenue)
names(dimnames(prod_duration_revenue)) <- c ( "prod_duration" , "revenue" )
# check the top of the dataframe
head(prod_duration_revenue)
# check the bottom of the dataframe
tail(prod_duration_revenue)
```
Users who spent a lot of time on the ecommerce site on product related pages ended up bringing in revenue to the company. Users who did not spend time in these pages also brought revenue though not as much as those who spent a lot of time

```{r}
# how does bounce rate affect revenue?
bounce_revenue <- table(ecommerce_unique$bounce_rates, ecommerce_unique$revenue)
names(dimnames(bounce_revenue)) <- c ( "bounce_rates" , "revenue" )
# check the top of the dataframe
head(bounce_revenue)
# check the bottom of the dataframe
tail(bounce_revenue)
```

0% bounce rate resulted in more revenue for the ecommerce company. The highest percentage of 0.15% bounce rate also resulted in more revenue but not as much as the zero percentage. 

```{r}
# how does exit rate affect revenue?
exit_revenue <- table(ecommerce_unique$exit_rates, ecommerce_unique$revenue)
names(dimnames(exit_revenue)) <- c ( "exit_rates" , "revenue" )
# check the top of the dataframe
head(exit_revenue)
# check the bottom of the dataframe
tail(exit_revenue)
```

0% exit rate resulted in a higher revenue return for the ecommerce company. 

```{r}
# how does page value affect revenue?
page_revenue <- table(ecommerce_unique$page_values, ecommerce_unique$revenue)
names(dimnames(page_revenue)) <- c ( "page_values" , "revenue" )
# check the top of the dataframe
page_revenue
```

Pages with a higher page value resulted in higher revenue returns for the ecommerce company. 

```{r}
# how do special days affect revenue?
special_revenue <- table(ecommerce_unique$special_day, ecommerce_unique$revenue)
names(dimnames(special_revenue)) <- c ( "special_day" , "revenue" )
# check the top of the dataframe
special_revenue
```

There are fewer visits to the site on Special days, which results in less revenue for the ecommerce company. More revenue is generated on non special days indicated by 0. This is expected as special days occur very few times in a year.

```{r}
# Which months bring highest revenue?
month_revenue <- table(ecommerce_unique$month, ecommerce_unique$revenue)
names(dimnames(month_revenue)) <- c ( "month" , "revenue" )
# check the top of the dataframe
month_revenue
```

The month of May has the highest number of visits to the site, followed by November while February had the least number of visits. May however, does not result in a higher revenue as November does. It could be that more users make a lot of purchase to gift their loved ones over festivities such as Thanksgiving holiday, Christmas holiday, New year's holiday. 

```{r}
# how does visitor type affect revenue?
visitor_revenue <- table(ecommerce_unique$visitor_type, ecommerce_unique$revenue)
names(dimnames(visitor_revenue)) <- c ( "visitor_type" , "revenue" )
# check the top of the dataframe
visitor_revenue
```

Most users who are not new to the ecommerce site make purchases which result in more revenue generation by the ecommerce company. 

```{r}
# how does bounce rate affect revenue?
weekend_revenue <- table(ecommerce_unique$weekend, ecommerce_unique$revenue)
names(dimnames(weekend_revenue)) <- c ( "weekend" , "revenue" )
# check the top of the dataframe
weekend_revenue
```

More revenue is generated for site visits made during weekdays


### Correlation Matrix
Find the correlations of the numerical columns and make a correlation matrix plot

```{r}
# find the correlations and round them off to 2 decimal places
#res <- round(cor(ecommerce_unique), 2 )
library (corrplot)

#corrplot(res, type = "full", order = "hclust", tl.col = "black", tl.srt = 45 )

```

# 10. Implementing the solution

## 10.1 Data Pre-processing
 
Before we begin modelling, we must ensure that the datatypes in the data we will use are in the appropriate mode i.e. numeric. 

```{r}
# check the datat types of the columns in the data
str(ecommerce_unique)
```

From the output, we can see that some of the fields we observed to be important during the EDA process are of character and logical types. The last 8 columns are categorical and can be converted to factor types for label encoding.

**Encoding categorical variables** 
The easiest way to do this is to convert the variables to factor datatypes and then to numeric datatypes. 

```{r}
# encoding categorical variables
ecommerce_unique$month <- as.numeric(as.factor(ecommerce_unique$month))

ecommerce_unique$operating_systems <- as.numeric(as.factor(ecommerce_unique$operating_systems))

ecommerce_unique$browser <- as.numeric(as.factor(ecommerce_unique$browser))

ecommerce_unique$region <- as.numeric(as.factor(ecommerce_unique$region))

ecommerce_unique$traffic_type <- as.numeric(as.factor(ecommerce_unique$traffic_type))

ecommerce_unique$visitor_type <- as.numeric(as.factor(ecommerce_unique$visitor_type))

ecommerce_unique$weekend <- as.numeric(as.factor(ecommerce_unique$weekend))

ecommerce_unique$revenue <- as.numeric(as.factor(ecommerce_unique$revenue))

```

Check the effect of the changes made

```{r}
# check the datatypes 
str(ecommerce_unique)
```

All the variables are now in numeric type.

**Feature Selection**

We exclude our target variable from the features 

```{r}
# remove the target variable from the features
ecommerce_new <- ecommerce_unique[, c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17)]

# save the target variable on a new dataframe
ecommerce_label <- ecommerce_unique[, "revenue"]

#check the top of the two dataframes
head(ecommerce_new)

head(ecommerce_label)
```

**Normalization**

Normalizing the variables in the dataset is done so that no particular attribute has more impact on the clustering algorithm than others

```{r}
#normalize function
normalize <- function(x){
  return ((x-min(x)) / (max(x)-min(x)))
}
```

```{r}
#apply the function on the features and check the top of the dataset
ecomm_new <- as.data.frame(lapply(ecommerce_new, normalize))

head(ecomm_new)
```

## 10.2 Modelling with K-Means Clustering

We can now build a clustering model with kmeans. Since we already know the expected number of clusters in our target field, we can specify the number of centroids,k=2(target revenue has two values TRUE and FALSE equal to two clusters)

```{r}
#modeling using kmeans, k=2
kmeans_model<- kmeans(ecomm_new,2) 
```

**Previewing the number of records in each cluster**

```{r}
# number of records in each cluster
kmeans_model$size
```

There are 2528 records in the first cluster and 9683 records in the second cluster, this sums to 12211 records which is the size of our initial data. 

**We can also get the value of cluster center datapoint for each variable.** 

```{r}
# getting cluster center datapoints
kmeans_model$centers 
```

**We can also get the cluster vector that shows the cluster where each record falls**

```{r}
# getting cluster vector
kmeans_model$cluster

```

We can also **plot to see how various fields were distributed in the clusters** and also compare the plot with the original dataset

```{r}
# plot to check administrative duration and informational duration in the clusters
plot(ecomm_new[c(2,4)], col = kmeans_model$cluster)
```

**Compare the plot with the initial distribution in the data** 

```{r}
plot(ecomm_new[c(2,4)], col = ecommerce_label)

```

The distribution on the model is similar to the distribution in the dataset. 

We can  **check the distribution on a table**

```{r}
table(kmeans_model$cluster, ecommerce_label)
```

The result of the table shows that cluster 1 corresponds to  the above table, cluster 1 corresponds to revenue = FALSE and cluster 2 corresponds to revenue = TRUE

We can see that the model did not perform so well since there are a couple number of misclassifications in the matrix. We can build a hierarchical model to observe if it will perform better than kmeans model. 

## 10.3 Hierarchical modeling

Compute the Euclidean distance between observations using the dist function

```{r}
#compute euclidean distance
d <- dist(ecomm_new, method = "euclidean")
```

We then build a hierachical model with the distance function and method average

```{r}
# build hierarchical model
hier <- hclust(d, method = "ward.D" )
```

Plotting the dendrogram
```{r}
# plot the obtained dendrogram
plot(hier, cex = 0.6, hang = -1)

```

It looks like the first smaller cluster corresponds to revenue = FALSE, which was the cluster with a few values, while the second large cluster with many other clusters corresponds to revenue = TRUE

```{r}
# install the package and load it: install.packages('ape')
#library(ape)
# plot basic tree
#plot(as.phylo(hier), cex = 0.9, label.offset = 1)
```

An alternative way to produce dendrograms is to specifically convert hclust objects into dendrograms objects. This makes it easier to truncate the dendrogram at specific points for easy interpretation
```{r}
# convert the hierarchical clustering object to dendrogram object
hcd = as.dendrogram(hier)
```

Now we can truncate the original dendrogram for easy interpretation
```{r}
plot(cut(hcd, h = 75)$upper, main = "Upper tree of cut at h=75")
plot(cut(hcd, h = 75)$lower[[2]], main = "Second branch of lower tree with cut at h=75")
```




















